{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "import napari\n",
    "from skimage import io\n",
    "import random\n",
    "import h5py\n",
    "from skimage import measure\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import subprocess\n",
    "import tables\n",
    "from napari_animation import AnimationWidget\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from parse_ara import *\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import brainrender\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import skeletonize\n",
    "from axon_data import brain2paths, brain2centers\n",
    "import os\n",
    "from util import json_to_points\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_points('https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=_i_hPWC-OM8TAw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"8613\"\n",
    "\n",
    "base_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/brain\" + brain + \"/\"\n",
    "\n",
    "if brain in brain2centers.keys():\n",
    "    centers_train = brain2centers[brain][0]\n",
    "    centers_val = brain2centers[brain][1] #annotate z slice 25, 50 and 75\n",
    "    print(f\"{len(centers_train)} training samples, {len(centers_val)} val samples\")\n",
    "\n",
    "mip = 0\n",
    "\n",
    "dir = brain2paths[brain][\"ab\"]\n",
    "vol_fg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "print(f\"fg shape: {vol_fg.shape} at {vol_fg.resolution}\")\n",
    "dir = brain2paths[brain][\"bg\"]\n",
    "vol_bg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "print(f\"bg shape: {vol_bg.shape} at {vol_bg.resolution}\")\n",
    "dir = brain2paths[brain][\"endo\"]\n",
    "vol_endo = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "print(f\"endo shape: {vol_endo.shape} at {vol_endo.resolution}\")\n",
    "\n",
    "if \"mask\" in brain2paths[brain].keys():\n",
    "    dir = brain2paths[brain][\"mask\"]\n",
    "    vol_mask = CloudVolume(dir, parallel=1, mip=mip, fill_missing=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_save = \"val\"\n",
    "\n",
    "if dataset_to_save == \"train\":\n",
    "    centers = centers_train\n",
    "elif dataset_to_save == \"val\":\n",
    "    centers = centers_val\n",
    "else:\n",
    "    raise ValueError(\"invalid dataset\")\n",
    "\n",
    "for i, center in enumerate(centers):\n",
    "    print(center)\n",
    "    image_fg = vol_fg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "    image_bg = vol_bg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "    image_endo = vol_endo[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "\n",
    "    image_2channel = np.stack([image_bg, image_fg, image_endo], axis=0)\n",
    "    \n",
    "    fname =base_dir + dataset_to_save + \"_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Image</span><span style=\"color: #000000; text-decoration-color: #000000\"> layer </span><span style=\"color: #008000; text-decoration-color: #008000\">'image_endo'</span><span style=\"color: #000000; text-decoration-color: #000000\"> at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x17c536a60</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mImage\u001b[0m\u001b[39m layer \u001b[0m\u001b[32m'image_endo'\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x17c536a60\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# center = centers_val[3]\n",
    "\n",
    "# image_fg = vol_fg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "# image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "# image_bg = vol_bg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "# image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "# image_endo = vol_endo[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "# image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "dset = \"val\"\n",
    "num = \"7\"\n",
    "\n",
    "fname = base_dir + dset + \"_\" + num + \".h5\"\n",
    "\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    pred = f.get(\"image_2channel\")\n",
    "    image_bg = pred[0, :, :, :]\n",
    "    image_fg = pred[1, :, :, :]\n",
    "    image_endo = pred[2, :, :, :]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg)\n",
    "viewer.add_image(image_bg)\n",
    "viewer.add_image(image_endo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = os.listdir(base_dir)\n",
    "files = [base_dir+f for f in files if \"val\" in f]\n",
    "files = [f for f in files if \"Labels.h5\" in f]\n",
    "\n",
    "num_pos_voxels = 0\n",
    "for fname in files:\n",
    "    f = h5py.File(fname, 'r')\n",
    "    gt = f.get('exported_data')\n",
    "    gt = gt[0,:,:,:]\n",
    "    pos_labels = gt == 2\n",
    "    num_pos_voxels += np.sum(pos_labels)\n",
    "\n",
    "print(num_pos_voxels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_total = 0\n",
    "false_pos_total = 0\n",
    "true_labels_total = 0\n",
    "\n",
    "files = os.listdir(base_dir)\n",
    "files = [base_dir+f for f in files if \"train\" in f]\n",
    "#need to filter for labels/probs fiiles\n",
    "\n",
    "for fname in files:\n",
    "    f = h5py.File(fname, 'r')\n",
    "    im = f.get('image_2channel')\n",
    "    im_bg = im[0,:,:,:]\n",
    "    im_fg = im[1,:,:,:]\n",
    "    im_endo = im[2,:,:,:]\n",
    "\n",
    "    fname = base_dir + \"train_\" + str(i) + \"-image_2channel_Labels.h5\"\n",
    "    f = h5py.File(fname, 'r')\n",
    "    gt = f.get('exported_data')\n",
    "    gt = gt[0,:,:,:]\n",
    "    pos_labels = gt == 2\n",
    "    num_pos_labels = np.sum(pos_labels)\n",
    "\n",
    "    fname = base_dir + \"train_\" + str(i) + \"-image_2channel_Probabilities.h5\"\n",
    "    f = h5py.File(fname, 'r')\n",
    "    seg = f.get('exported_data')\n",
    "    seg = seg[1,:,:,:]\n",
    "    mask = seg > 0.5\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "    true_pos_total += true_pos\n",
    "    false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "    false_pos_total += false_pos\n",
    "    true_labels = np.sum(pos_labels)\n",
    "    true_labels_total += true_labels\n",
    "    \n",
    "    if num_pos_labels > 0:\n",
    "        precision = true_pos/(true_pos + false_pos)\n",
    "        recall = true_pos/true_labels\n",
    "        print(f\"Example {i}: precision: {precision}, recall: {recall}\")\n",
    "    else:\n",
    "        print(f\"Example {i}: 0 positive labels, false positive rate is: {false_pos/np.sum(gt == 1)}\")\n",
    "\n",
    "    '''\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(im_bg)\n",
    "    viewer.add_image(im_fg)\n",
    "    viewer.add_labels(gt)\n",
    "    viewer.add_labels(mask)\n",
    "    '''\n",
    "print(f\"Total precision: {true_pos_total/(true_pos_total + false_pos_total)} total recall: {true_pos_total/true_labels_total} with {true_labels_total} total positive voxels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Val results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 total validation subvolumes\n",
      "Thresh: 0.02 --- Total prec.: 0.370 total rec.: 1.000 w/2028/12786 total pos/neg voxels. F-score: 0.5399\n",
      "Thresh: 0.04 --- Total prec.: 0.496 total rec.: 0.998 w/2028/12786 total pos/neg voxels. F-score: 0.6625\n",
      "Thresh: 0.06 --- Total prec.: 0.592 total rec.: 0.995 w/2028/12786 total pos/neg voxels. F-score: 0.7422\n",
      "Thresh: 0.08 --- Total prec.: 0.661 total rec.: 0.994 w/2028/12786 total pos/neg voxels. F-score: 0.7943\n",
      "Thresh: 0.10 --- Total prec.: 0.719 total rec.: 0.988 w/2028/12786 total pos/neg voxels. F-score: 0.8322\n",
      "Thresh: 0.12 --- Total prec.: 0.766 total rec.: 0.984 w/2028/12786 total pos/neg voxels. F-score: 0.8612\n",
      "Thresh: 0.14 --- Total prec.: 0.802 total rec.: 0.980 w/2028/12786 total pos/neg voxels. F-score: 0.8817\n",
      "Thresh: 0.16 --- Total prec.: 0.838 total rec.: 0.978 w/2028/12786 total pos/neg voxels. F-score: 0.9026\n",
      "Thresh: 0.18 --- Total prec.: 0.862 total rec.: 0.976 w/2028/12786 total pos/neg voxels. F-score: 0.9154\n",
      "Thresh: 0.20 --- Total prec.: 0.884 total rec.: 0.975 w/2028/12786 total pos/neg voxels. F-score: 0.9273\n",
      "Thresh: 0.22 --- Total prec.: 0.905 total rec.: 0.974 w/2028/12786 total pos/neg voxels. F-score: 0.9382\n",
      "Thresh: 0.24 --- Total prec.: 0.923 total rec.: 0.970 w/2028/12786 total pos/neg voxels. F-score: 0.9457\n",
      "Thresh: 0.26 --- Total prec.: 0.934 total rec.: 0.967 w/2028/12786 total pos/neg voxels. F-score: 0.9501\n",
      "Thresh: 0.28 --- Total prec.: 0.944 total rec.: 0.964 w/2028/12786 total pos/neg voxels. F-score: 0.9537\n",
      "Thresh: 0.30 --- Total prec.: 0.950 total rec.: 0.959 w/2028/12786 total pos/neg voxels. F-score: 0.9546\n",
      "Thresh: 0.32 --- Total prec.: 0.957 total rec.: 0.957 w/2028/12786 total pos/neg voxels. F-score: 0.9571\n",
      "Thresh: 0.34 --- Total prec.: 0.967 total rec.: 0.954 w/2028/12786 total pos/neg voxels. F-score: 0.9603\n",
      "Thresh: 0.36 --- Total prec.: 0.971 total rec.: 0.951 w/2028/12786 total pos/neg voxels. F-score: 0.9609\n",
      "Thresh: 0.38 --- Total prec.: 0.974 total rec.: 0.947 w/2028/12786 total pos/neg voxels. F-score: 0.9600\n",
      "Thresh: 0.40 --- Total prec.: 0.976 total rec.: 0.941 w/2028/12786 total pos/neg voxels. F-score: 0.9583\n",
      "Thresh: 0.42 --- Total prec.: 0.979 total rec.: 0.932 w/2028/12786 total pos/neg voxels. F-score: 0.9548\n",
      "Thresh: 0.44 --- Total prec.: 0.981 total rec.: 0.929 w/2028/12786 total pos/neg voxels. F-score: 0.9547\n",
      "Thresh: 0.46 --- Total prec.: 0.983 total rec.: 0.922 w/2028/12786 total pos/neg voxels. F-score: 0.9514\n",
      "Thresh: 0.48 --- Total prec.: 0.985 total rec.: 0.912 w/2028/12786 total pos/neg voxels. F-score: 0.9470\n",
      "Thresh: 0.50 --- Total prec.: 0.985 total rec.: 0.904 w/2028/12786 total pos/neg voxels. F-score: 0.9432\n",
      "Thresh: 0.52 --- Total prec.: 0.988 total rec.: 0.897 w/2028/12786 total pos/neg voxels. F-score: 0.9401\n",
      "Thresh: 0.54 --- Total prec.: 0.990 total rec.: 0.891 w/2028/12786 total pos/neg voxels. F-score: 0.9375\n",
      "Thresh: 0.56 --- Total prec.: 0.989 total rec.: 0.879 w/2028/12786 total pos/neg voxels. F-score: 0.9311\n",
      "Thresh: 0.58 --- Total prec.: 0.990 total rec.: 0.866 w/2028/12786 total pos/neg voxels. F-score: 0.9243\n",
      "Thresh: 0.60 --- Total prec.: 0.991 total rec.: 0.846 w/2028/12786 total pos/neg voxels. F-score: 0.9125\n",
      "Thresh: 0.62 --- Total prec.: 0.992 total rec.: 0.826 w/2028/12786 total pos/neg voxels. F-score: 0.9016\n",
      "Thresh: 0.64 --- Total prec.: 0.994 total rec.: 0.802 w/2028/12786 total pos/neg voxels. F-score: 0.8879\n",
      "Thresh: 0.66 --- Total prec.: 0.996 total rec.: 0.785 w/2028/12786 total pos/neg voxels. F-score: 0.8776\n",
      "Thresh: 0.68 --- Total prec.: 0.997 total rec.: 0.762 w/2028/12786 total pos/neg voxels. F-score: 0.8642\n",
      "Thresh: 0.70 --- Total prec.: 0.997 total rec.: 0.732 w/2028/12786 total pos/neg voxels. F-score: 0.8445\n",
      "Thresh: 0.72 --- Total prec.: 0.999 total rec.: 0.695 w/2028/12786 total pos/neg voxels. F-score: 0.8194\n",
      "Thresh: 0.74 --- Total prec.: 1.000 total rec.: 0.658 w/2028/12786 total pos/neg voxels. F-score: 0.7936\n",
      "Thresh: 0.76 --- Total prec.: 1.000 total rec.: 0.624 w/2028/12786 total pos/neg voxels. F-score: 0.7683\n",
      "Thresh: 0.78 --- Total prec.: 1.000 total rec.: 0.586 w/2028/12786 total pos/neg voxels. F-score: 0.7392\n",
      "Thresh: 0.80 --- Total prec.: 1.000 total rec.: 0.553 w/2028/12786 total pos/neg voxels. F-score: 0.7120\n",
      "Thresh: 0.82 --- Total prec.: 1.000 total rec.: 0.508 w/2028/12786 total pos/neg voxels. F-score: 0.6736\n",
      "Thresh: 0.84 --- Total prec.: 1.000 total rec.: 0.459 w/2028/12786 total pos/neg voxels. F-score: 0.6288\n",
      "Thresh: 0.86 --- Total prec.: 1.000 total rec.: 0.412 w/2028/12786 total pos/neg voxels. F-score: 0.5833\n",
      "Thresh: 0.88 --- Total prec.: 1.000 total rec.: 0.352 w/2028/12786 total pos/neg voxels. F-score: 0.5208\n",
      "Thresh: 0.90 --- Total prec.: 1.000 total rec.: 0.288 w/2028/12786 total pos/neg voxels. F-score: 0.4472\n",
      "Thresh: 0.92 --- Total prec.: 1.000 total rec.: 0.222 w/2028/12786 total pos/neg voxels. F-score: 0.3632\n",
      "Thresh: 0.94 --- Total prec.: 1.000 total rec.: 0.151 w/2028/12786 total pos/neg voxels. F-score: 0.2630\n",
      "Thresh: 0.96 --- Total prec.: 1.000 total rec.: 0.085 w/2028/12786 total pos/neg voxels. F-score: 0.1564\n",
      "Thresh: 0.98 --- Total prec.: 1.000 total rec.: 0.036 w/2028/12786 total pos/neg voxels. F-score: 0.0695\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">matplotlib.legend.Legend</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x17c5d1a90</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mmatplotlib.legend.Legend\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x17c5d1a90\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacing =  0.02\n",
    "thresholds = np.arange(spacing, 1.0, spacing)\n",
    "precisions = []\n",
    "recalls = []\n",
    "best_fscore = 0\n",
    "\n",
    "files = os.listdir(base_dir)\n",
    "files = [base_dir+f for f in files if \"val\" in f]\n",
    "files = [f for f in files if \"_Probabilities.h5\" in f]\n",
    "fiiles = [f for f in files if \"val\" in f]\n",
    "\n",
    "print(f\"{len(files)} total validation subvolumes\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    true_pos_total = 0\n",
    "    false_pos_total = 0\n",
    "    true_labels_total = 0\n",
    "    true_labels_total_neg = 0\n",
    "    for fname_prob in files:\n",
    "\n",
    "        fname_im = fname_prob[:-17] + \".h5\"\n",
    "        f = h5py.File(fname_im, 'r')\n",
    "        im = f.get('image_2channel')\n",
    "        im_bg = im[0,:,:,:]\n",
    "        im_fg = im[1,:,:,:]\n",
    "\n",
    "        fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "        f = h5py.File(fname_lab, 'r')\n",
    "        gt = f.get('exported_data')\n",
    "        gt = gt[0,:,:,:]\n",
    "        pos_labels = gt == 2\n",
    "        neg_labels = gt == 1\n",
    "\n",
    "        f = h5py.File(fname_prob, 'r')\n",
    "        seg = f.get('exported_data')\n",
    "        seg = seg[1,:,:,:]\n",
    "        mask = seg > threshold\n",
    "\n",
    "        true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "        true_pos_total += true_pos\n",
    "        false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "        false_pos_total += false_pos\n",
    "        true_labels = np.sum(pos_labels)\n",
    "        true_labels_total += true_labels\n",
    "        true_labels_neg = np.sum(neg_labels)\n",
    "        true_labels_total_neg += true_labels_neg\n",
    "        \n",
    "    precision_total = true_pos_total/(true_pos_total + false_pos_total)\n",
    "    recall_total = true_pos_total/true_labels_total\n",
    "    fscore = 2/(1/precision_total+1/recall_total)\n",
    "    print(f\"Thresh: {threshold:.2f} --- Total prec.: {precision_total:.3f} total rec.: {recall_total:.3f} w/{true_labels_total}/{true_labels_total_neg} total pos/neg voxels. F-score: {fscore:.4f}\")\n",
    "    if fscore > best_fscore:\n",
    "        best_fscore = fscore\n",
    "        best_prec = precision_total\n",
    "        best_recall = recall_total\n",
    "        best_threshold = threshold\n",
    "    precisions.append(precision_total) \n",
    "    recalls.append(recall_total)\n",
    "plt.plot(recalls, precisions, label='Prec-Rec Curve')\n",
    "plt.scatter([best_recall], [best_prec], c='red', label=f\"Best F-score: {best_fscore:.3f} (thresh {best_threshold:.2f})\")\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title(f'Validation Brain {brain} w/{true_labels_total} Total Pos. Voxels')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_points(\"https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=Tizkn7VMAv6B6Q\", round=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname_prob in files:\n",
    "    fname_im = fname_prob[:-17] + \".h5\"\n",
    "    f = h5py.File(fname_im, 'r')\n",
    "    im = f.get('image_2channel')\n",
    "    im_bg = im[0,:,:,:]\n",
    "    im_fg = im[1,:,:,:]\n",
    "    im_endo = im[2,:,:,:]\n",
    "\n",
    "    fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "    f = h5py.File(fname_lab, 'r')\n",
    "    gt = f.get('exported_data')\n",
    "    gt = gt[0,:,:,:]\n",
    "    pos_labels = gt == 2\n",
    "\n",
    "    f = h5py.File(fname_prob, 'r')\n",
    "    seg = f.get('exported_data')\n",
    "    seg = seg[1,:,:,:]\n",
    "    mask = seg > best_threshold\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "    true_pos_total += true_pos\n",
    "    false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "    false_pos_total += false_pos\n",
    "    true_labels = np.sum(pos_labels)\n",
    "    true_labels_total += true_labels\n",
    "    \n",
    "\n",
    "    precision = true_pos/(true_pos + false_pos)\n",
    "    recall = true_pos/true_labels\n",
    "    fscore = 2/(1/precision+1/recall)\n",
    "    print(f\"prec {precision} rec {recall} f {fscore}\")\n",
    "    if fscore < 0.75:\n",
    "        print(fname_prob)\n",
    "        name = fname_prob.split(\"/\")[-1]\n",
    "        viewer = napari.Viewer(ndisplay=3)\n",
    "        viewer.add_image(im_bg, name=name[:-17])\n",
    "        viewer.add_image(im_fg)\n",
    "        viewer.add_image(im_endo)\n",
    "        viewer.add_labels(gt)\n",
    "        viewer.add_labels(mask, name=f\"p:{precision:.2f} r{recall:.2f}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_points(\"https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=V1ZmxgI5NeFOaw\", round=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make annotation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir = \"s3://smartspim-precomputed-volumes/2022_01_14/8613/axon_mask\"\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    encoding        = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution      = vol_bg.resolution, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = vol_bg.voxel_offset, # x,y,z offset in voxels from the origin\n",
    "    # mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 128, 128, 2 ], # units are voxels\n",
    "    volume_size     = vol_bg.volume_size, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol_mask = CloudVolume(dir, info=info)\n",
    "vol_mask.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vol = CloudVolume(\"s3://smartspim-precomputed-volumes/2022_01_14/8613/Ch_488\")\n",
    "print(vol.info)\n",
    "\n",
    "\n",
    "vol2 = CloudVolume(\"s3://smartspim-precomputed-volumes/2022_01_14/8613/Ch_561\", info=vol.info)\n",
    "vol2.commit_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cannot write to https link, can write to s3 link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whole brain results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download from cloud\n",
    "centers = [[2304, 3840, 2100], [2560, 3840, 1800]]\n",
    "\n",
    "for i,center in enumerate(centers):\n",
    "    image_fg = vol_fg[center[0]:center[0]+256,center[1]:center[1]+256, center[2]:center[2]+300]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "    image_bg = vol_bg[center[0]:center[0]+256,center[1]:center[1]+256, center[2]:center[2]+300]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "    mask_s3 = vol_mask[center[0]:center[0]+256,center[1]:center[1]+256, center[2]:center[2]+300]\n",
    "    mask_s3 = mask_s3[:,:,:,0]\n",
    "\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/test_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/image_0.h5\"\n",
    "\n",
    "subprocess.run([\"/Applications/ilastik-1.3.3post3-OSX.app/Contents/ilastik-release/run_ilastik.sh\",  \"--headless\", \"--project=/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/matt_benchmark_formal.ilp\", fname], stdout=subprocess.PIPE, stderr=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample axon mask layer with igneous (this is only partial code, see igneous github for other code snippets)\n",
    "\n",
    "layer_path = \"s3://smartspim-precomputed-volumes/2021_07_15_Sert_Cre_R/axon_mask\"\n",
    "\n",
    "tasks = tc.create_downsampling_tasks(\n",
    "    layer_path, # e.g. 'gs://bucket/dataset/layer'\n",
    "    mip=0, # Start downsampling from this mip level (writes to next level up)\n",
    "    fill_missing=True, # Ignore missing chunks and fill them with black\n",
    "    axis='z', \n",
    "    num_mips=5, # number of downsamples to produce. Downloaded shape is chunk_size * 2^num_mip\n",
    "    chunk_size=None, # manually set chunk size of next scales, overrides preserve_chunk_size\n",
    "    preserve_chunk_size=True, # use existing chunk size, don't halve to get more downsamples\n",
    "    sparse=False, # for sparse segmentation, allow inflation of pixels against background\n",
    "    bounds=None, # mip 0 bounding box to downsample \n",
    "    encoding=None, # e.g. 'raw', 'compressed_segmentation', etc\n",
    "    delete_black_uploads=False, # issue a delete instead of uploading files containing all background\n",
    "    background_color=0, # Designates the background color\n",
    "    compress='gzip', # None, 'gzip', and 'br' (brotli) are options\n",
    "    factor=(2,2,2), # common options are (2,2,1) and (2,2,2)\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download higher mip\n",
    "\n",
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_07_15_Sert_Cre_R/axon_mask\"\n",
    "vol_mask_ds = CloudVolume(dir, parallel=1, mip=1, fill_missing=False)\n",
    "print(vol_mask_ds.shape)\n",
    "\n",
    "data = vol_mask_ds[:,:,0,0]\n",
    "data = data.astype('int8')\n",
    "print(data.nbytes)\n",
    "# print(np.unique(data))\n",
    "data = data[:,:,:,0]\n",
    "data = np.swapaxes(data, 0,2) #must do this\n",
    "print(data.shape)\n",
    "\n",
    "io.imsave(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/axon_mask_.tif\", data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View coronal heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = brain2paths[brain][\"mask\"]\n",
    "vol_mask = CloudVolume(dir, parallel=1, mip=3, fill_missing=True)\n",
    "print(vol_mask.shape)\n",
    "\n",
    "\n",
    "dir = brain2paths[brain][\"atlas\"]\n",
    "vol_atlas = CloudVolume(dir, parallel=1, mip=0, fill_missing=True)\n",
    "print(vol_atlas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z_atlas in range(0, vol_atlas.shape[2], 1000):\n",
    "    atlas = np.squeeze(vol_atlas[:,:,z_atlas,0])\n",
    "    mask = np.squeeze(vol_mask[:,:,int(z_atlas/8),0])\n",
    "    viewer = napari.Viewer(ndisplay=2)\n",
    "    viewer.add_image(mask)\n",
    "    viewer.add_labels(atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample\n",
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/registered_2.img\"\n",
    "im = io.imread(im_path)\n",
    "print(im.shape)\n",
    "print(np.unique(im))\n",
    "\n",
    "im = im.astype('float')\n",
    "\n",
    "im_ds = ndi.zoom(im, (0.4,0.4,0.4))\n",
    "print(im_ds.shape)\n",
    "print(np.unique(im_ds))\n",
    "\n",
    "np.save(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/registered_3_ds.npy\", im_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/axon_mask_1_0.tif\"\n",
    "im = io.imread(im_path)\n",
    "print(im.shape)\n",
    "print(np.sum(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"brain3\"\n",
    "\n",
    "# im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain3/register/registered_3_ds.npy\"\n",
    "# im = np.load(im_path)\n",
    "# print(im.shape)\n",
    "\n",
    "# im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain3/register/axon_mask_3.tif\"\n",
    "# im_unreg = io.imread(im_path)\n",
    "# print(im_unreg.shape)\n",
    "\n",
    "\n",
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/\" + brain + \"/register/registered_1.img\"\n",
    "im_reg2 = io.imread(im_path)\n",
    "print(im_reg2.shape)\n",
    "\n",
    "# im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/\" + brain + \"/register/registered_3.img\"\n",
    "# im_reg3 = io.imread(im_path)\n",
    "# print(im_reg3.shape)\n",
    "\n",
    "# vol = CloudVolume(\n",
    "#     \"s3://open-neurodata/ara_2016/sagittal_10um/annotation_10um_2017\", mip=0, use_https=True\n",
    "# )\n",
    "# print(vol.shape)\n",
    "# atlas = vol[:,:,:,:]\n",
    "# atlas = np.squeeze(atlas).T\n",
    "# print(atlas.shape)\n",
    "# len(np.unique(atlas))\n",
    "\n",
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/ara_10um.tif\"\n",
    "atlas = io.imread(im_path)\n",
    "print(atlas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = ndi.gaussian_filter(im_reg2.astype('float'), sigma=3)\n",
    "#smooth = ndi.zoom(smooth, (0.4,0.4,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "animation_widget = AnimationWidget(viewer)\n",
    "viewer.window.add_dock_widget(animation_widget, area='right')\n",
    "#viewer.add_image(im)\n",
    "viewer.add_image(smooth)\n",
    "#viewer.add_image(im_reg2)\n",
    "#viewer.add_image(im_reg3)\n",
    "viewer.add_labels(atlas)\n",
    "napari.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in [180, 430, 680, 1030, 1280]:\n",
    "\n",
    "    slice = atlas[:,:,z]\n",
    "    slice_data = smooth[:,:,z]#np.sum(im_reg[:,:,z], axis=2)\n",
    "    mn = np.amin(slice_data)\n",
    "    print(np.unique(slice_data))\n",
    "    slice_data[slice == 0] = mn\n",
    "    labels = measure.label(slice)\n",
    "    #plt.imshow(labels)\n",
    "\n",
    "    borders = 0*labels\n",
    "    for label in np.unique(labels):\n",
    "        if label != 0:\n",
    "            mask = np.array(labels == label, dtype='int')\n",
    "            erode = np.array(ndi.binary_erosion(mask))\n",
    "            outline = mask - erode\n",
    "            borders += outline\n",
    "\n",
    "    print(np.unique(borders))\n",
    "    borders = borders.astype('float')\n",
    "    borders_layer = np.zeros((borders.shape[0],borders.shape[1],4))\n",
    "    for rgba in range(borders_layer.shape[2]):\n",
    "        borders_layer[:,:,rgba] = borders\n",
    "\n",
    "\n",
    "    slice_data = ndi.rotate(slice_data, 270)\n",
    "    plt.imshow(slice_data, cmap='inferno')\n",
    "    borders_layer = ndi.rotate(borders_layer, 270)\n",
    "    plt.imshow(borders_layer, cmap='gray')\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    fig.savefig('/Users/thomasathey/Desktop/' + str(z) + '.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = {}\n",
    "for x in tqdm(np.arange(0, vol_mask.shape[0], 128)):\n",
    "    x2 = np.amin([x+128, vol_mask.shape[0]])\n",
    "    for y in tqdm(np.arange(0, vol_mask.shape[1], 128), leave=False):\n",
    "        y2 = np.amin([x+128, vol_mask.shape[1]])\n",
    "        for z in tqdm(np.arange(0, vol_mask.shape[2], 128), leave=False):\n",
    "            z2 = np.amin([x+128, vol_mask.shape[2]])\n",
    "            labels = vol_reg[x:x2,y:y2,z:z2]\n",
    "            labels_unique = np.unique(labels)\n",
    "            mask = vol_mask[x:x2,y:y2,z:z2]\n",
    "\n",
    "            for unq in labels_unique:\n",
    "                if unq in volumes.keys():\n",
    "                    cur_vol = volumes[unq][1]\n",
    "                    cur_total = volumes[unq][0]\n",
    "                else:\n",
    "                    cur_vol = 0\n",
    "                    cur_total = 0\n",
    "                cur_vol += np.sum(mask[labels == unq])\n",
    "                cur_total += np.sum(labels == unq)\n",
    "                volumes[unq] = [cur_total, cur_vol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read quantification dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/brain3/vol_density.pkl\"\n",
    "with open(path, \"rb\") as f:\n",
    "   quantification_dict_3 = pickle.load(f)\n",
    "\n",
    "\n",
    "path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/brain4/vol_density.pkl\"\n",
    "with open(path, \"rb\") as f:\n",
    "   quantification_dict_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [688, 698, 1089, 583, 477, 803, 703, 1097, 549, 313, 1065]\n",
    "allen_regions = [315, 698, 1089, 703, 477, 803, 549, 1097, 313, 771, 354, 512] #https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantification_dicts = {\"B\": quantification_dict_3, \"R\": quantification_dict_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = json.load(open('/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/deisseroth/ara_structure_ontology.json','r'))\n",
    "\n",
    "tree = build_tree(f)\n",
    "stack = [tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [tree]\n",
    "cur_level = -1\n",
    "counter = 0\n",
    "G = nx.DiGraph()\n",
    "max_level = 0\n",
    "\n",
    "\n",
    "while len(queue) > 0:\n",
    "    node = queue.pop(0)\n",
    "    if node.level > max_level:\n",
    "        max_level = node.level\n",
    "    G.add_node(node.id, level = node.level, st_level = node.st_level, name = node.name, acronym = node.acronym, label = str(node.st_level) + \") \" +node.name)\n",
    "    for brain in quantification_dicts.keys():\n",
    "        G.nodes[node.id][brain + \" axon\"] = 0\n",
    "        G.nodes[node.id][brain + \" total\"] = 0\n",
    "    if node.parent_id is not None:\n",
    "        G.add_edge(node.parent_id, node.id)\n",
    "\n",
    "    queue += node.children\n",
    "\n",
    "i_test = 0\n",
    "print(f\"Max level: {max_level}\")\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])\n",
    "for brain,quantification_dict in quantification_dicts.items():\n",
    "    for key in quantification_dict.keys():\n",
    "        if key in G.nodes:\n",
    "            G.nodes[key][brain + \" axon\"] = G.nodes[key][brain + \" axon\"] + float(quantification_dict[key][1])\n",
    "            G.nodes[key][brain + \" total\"] = G.nodes[key][brain + \" total\"] + float(quantification_dict[key][0])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    for lvl in range(max_level, 0, -1):\n",
    "        for node in G.nodes:\n",
    "            if G.nodes[node]['level'] == lvl:\n",
    "                parent = list(G.in_edges(node))[0][0]\n",
    "                G.nodes[parent][brain + \" axon\"] = G.nodes[parent][brain + \" axon\"] + G.nodes[node][brain + \" axon\"]\n",
    "                G.nodes[parent][brain + \" total\"] = G.nodes[parent][brain + \" total\"] + G.nodes[node][brain + \" total\"]\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas + seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    total = 0\n",
    "    for node in G.nodes:\n",
    "        total += G.nodes[node][brain + \" axon\"]\n",
    "    totals[brain] = total\n",
    "\n",
    "axon_vols = []\n",
    "axon_denss = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "for region in regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    children = list(G.successors(region))\n",
    "    for child in children:\n",
    "        for brain in quantification_dicts.keys():\n",
    "            axon_vols.append(G.nodes[child][brain + \" axon\"]/totals[brain]*100)\n",
    "            if G.nodes[child][brain + \" total\"] == 0 and G.nodes[child][brain + \" axon\"] == 0:\n",
    "                axon_denss.append(0)\n",
    "            elif G.nodes[child][brain + \" total\"] == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                axon_denss.append(G.nodes[child][brain + \" axon\"]/G.nodes[child][brain + \" total\"]*100)\n",
    "\n",
    "            if brain in [\"B\", \"R\"]:\n",
    "                gene.append(\"sert cre\")\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "            region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "d = {\"Percent Total Axon Volume (%)\": axon_vols, \"Axon Density (%)\": axon_denss, \"Gene\": gene, \"Subregion\": subregion_name, \"Region\": region_name}\n",
    "df = pd.DataFrame(data = d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(25, 18))\n",
    "fig.suptitle('Detected Output Axons')\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "sns.stripplot(ax = axes[0], x = \"Percent Total Axon Volume (%)\", y = \"Subregion\",  hue= \"Gene\", data=df)\n",
    "\n",
    "sns.stripplot(ax = axes[1], x = \"Axon Density (%)\", y = \"Subregion\",  hue= \"Gene\", data=df)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Allen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "subregions_list = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    children = list(G.successors(region))\n",
    "    for child in children:\n",
    "        if child not in subregions_list:\n",
    "            subregions_list.append(child)\n",
    "\n",
    "\n",
    "        for brain in quantification_dicts.keys():\n",
    "            if G.nodes[child][brain + \" total\"] == 0 and G.nodes[child][brain + \" axon\"] == 0:\n",
    "                axon_denss.append(0)\n",
    "            elif G.nodes[child][brain + \" total\"] == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                axon_denss.append(G.nodes[child][brain + \" axon\"]/G.nodes[child][brain + \" total\"])\n",
    "\n",
    "            if brain in [\"B\", \"R\"]:\n",
    "                gene.append(brain)\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "\n",
    "        \n",
    "    region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse('/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/deisseroth/sert_exp.xml')\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "        if region in subregions_list and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(f\"id: {region} hemi: {hemi}, density: {density}, name: {name}\")\n",
    "            subregion_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "\n",
    "\n",
    "\n",
    "d = {\"Axon Density\": axon_denss, \"Gene\": gene, \"Subregion\": subregion_name}\n",
    "df = pd.DataFrame(data = d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(20, 10))\n",
    "fig.suptitle('Detected Output Axons')\n",
    "\n",
    "sns.barplot(x = \"Axon Density\", y = \"Subregion\",  hue= \"Gene\", data=df)\n",
    "axes.set_title(\"Density\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "axon_vols = []\n",
    "gene = []\n",
    "region_name = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    for brain in quantification_dicts.keys():\n",
    "        if G.nodes[region][brain + \" total\"] == 0 and G.nodes[region][brain + \" axon\"] == 0:\n",
    "            axon_denss.append(0)\n",
    "        elif G.nodes[region][brain + \" total\"] == 0:\n",
    "            raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "        else:\n",
    "            axon_denss.append(G.nodes[region][brain + \" axon\"]/G.nodes[region][brain + \" total\"])\n",
    "            axon_vols.append(G.nodes[region][brain + \" axon\"]*np.product([1.82,1.82,2])*10**(-9))\n",
    "\n",
    "\n",
    "        if brain in [\"B\", \"R\"]:\n",
    "            gene.append(\"Sample \" + brain)\n",
    "        \n",
    "        region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse('/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/deisseroth/sert_exp.xml')\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "            elif item.tag == \"projection-volume\":\n",
    "                volume = float(item.text)\n",
    "        if region in allen_regions and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(f\"id: {region} hemi: {hemi}, density: {density}, volume: {volume}, name: {name}\")\n",
    "            region_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "            axon_vols.append(volume)\n",
    "\n",
    "\n",
    "\n",
    "d = {\"Axon Density\": axon_denss, \"Axon Volume ($mm^3$)\": axon_vols, \"Gene\": gene, \"Region\": region_name}\n",
    "df = pd.DataFrame(data = d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle('Comparing Axon Volumes to Allen Experiment')\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "sns.barplot(ax = axes[0], x = \"Axon Density\", y = \"Region\",  hue= \"Gene\", order = list(df[df[\"Gene\"] == \"Allen\"].sort_values('Axon Density', ascending=False).loc[:,'Region']), data=df)\n",
    "#axes[0].set_title(\"Density\")\n",
    "\n",
    "sns.barplot(ax = axes[1], x = \"Axon Volume ($mm^3$)\", y = \"Region\",  hue= \"Gene\", order = list(df[df[\"Gene\"] == \"Allen\"].sort_values('Axon Density', ascending=False).loc[:,'Region']), data=df)\n",
    "#axes[1].set_title(\"Axon Volume\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
