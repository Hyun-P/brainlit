{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "import napari\n",
    "from skimage import io\n",
    "import random\n",
    "import h5py\n",
    "from skimage import measure\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import subprocess\n",
    "import tables\n",
    "from napari_animation import AnimationWidget\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from parse_ara import *\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import brainrender\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import skeletonize\n",
    "from axon_data import brain2paths, brain2centers\n",
    "import os\n",
    "from util import json_to_points\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im0 = io.imread(\"/Users/thomasathey/Documents/mimlab/mouselight/axon_mapping/0.tif\")\n",
    "im1 = io.imread(\"/Users/thomasathey/Documents/mimlab/mouselight/axon_mapping/1.tif\")\n",
    "res = (1, 0.3, 0.3)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im0, scale = res)\n",
    "viewer.add_image(im1, scale  = res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 training samples, 32 val samples\n",
      "(5602, 8800, 4200, 1)\n"
     ]
    }
   ],
   "source": [
    "brain = \"3\"\n",
    "\n",
    "base_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/brain\" + brain + \"/\"\n",
    "\n",
    "centers_train = brain2centers[brain][0]\n",
    "centers_val = brain2centers[brain][0] #annotate z slice 25, 50 and 75\n",
    "print(f\"{len(centers_train)} training samples, {len(centers_val)} val samples\")\n",
    "\n",
    "dir = brain2paths[brain][\"ab\"]\n",
    "vol_fg = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "dir = brain2paths[brain][\"bg\"]\n",
    "vol_bg = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "dir = brain2paths[brain][\"endo\"]\n",
    "vol_endo = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "dir = brain2paths[brain][\"mask\"]\n",
    "vol_mask = CloudVolume(dir, parallel=1, mip=0, fill_missing=True)\n",
    "\n",
    "print(vol_bg.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_save = \"val\"\n",
    "\n",
    "if dataset_to_save == \"train\":\n",
    "    centers = centers_train\n",
    "elif dataset_to_save == \"val\":\n",
    "    centers = centers_val\n",
    "else:\n",
    "    raise ValueError(\"invalid dataset\")\n",
    "\n",
    "for i, center in enumerate(centers_train):\n",
    "    if i < 7:\n",
    "        continue\n",
    "    image_fg = vol_fg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "    image_bg = vol_bg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "    image_endo = vol_endo[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "\n",
    "    image_2channel = np.stack([image_bg, image_fg, image_endo], axis=0)\n",
    "    \n",
    "    fname =base_dir + dataset_to_save + \"_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = centers_train[2]\n",
    "\n",
    "image_fg = vol_fg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "image_bg = vol_bg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "image_endo = vol_endo[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg)\n",
    "viewer.add_image(image_bg)\n",
    "viewer.add_image(image_endo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_total = 0\n",
    "false_pos_total = 0\n",
    "true_labels_total = 0\n",
    "\n",
    "files = os.listdir(base_dir)\n",
    "files = [base_dir+f for f in files if \"train\" in f]\n",
    "#need to filter for labels/probs fiiles\n",
    "\n",
    "for fname in files:\n",
    "    f = h5py.File(fname, 'r')\n",
    "    im = f.get('image_2channel')\n",
    "    im_bg = im[0,:,:,:]\n",
    "    im_fg = im[1,:,:,:]\n",
    "    im_endo = im[2,:,:,:]\n",
    "\n",
    "    fname = base_dir + \"train_\" + str(i) + \"-image_2channel_Labels.h5\"\n",
    "    f = h5py.File(fname, 'r')\n",
    "    gt = f.get('exported_data')\n",
    "    gt = gt[0,:,:,:]\n",
    "    pos_labels = gt == 2\n",
    "    num_pos_labels = np.sum(pos_labels)\n",
    "\n",
    "    fname = base_dir + \"train_\" + str(i) + \"-image_2channel_Probabilities.h5\"\n",
    "    f = h5py.File(fname, 'r')\n",
    "    seg = f.get('exported_data')\n",
    "    seg = seg[1,:,:,:]\n",
    "    mask = seg > 0.5\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "    true_pos_total += true_pos\n",
    "    false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "    false_pos_total += false_pos\n",
    "    true_labels = np.sum(pos_labels)\n",
    "    true_labels_total += true_labels\n",
    "    \n",
    "    if num_pos_labels > 0:\n",
    "        precision = true_pos/(true_pos + false_pos)\n",
    "        recall = true_pos/true_labels\n",
    "        print(f\"Example {i}: precision: {precision}, recall: {recall}\")\n",
    "    else:\n",
    "        print(f\"Example {i}: 0 positive labels, false positive rate is: {false_pos/np.sum(gt == 1)}\")\n",
    "\n",
    "    '''\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(im_bg)\n",
    "    viewer.add_image(im_fg)\n",
    "    viewer.add_labels(gt)\n",
    "    viewer.add_labels(mask)\n",
    "    '''\n",
    "print(f\"Total precision: {true_pos_total/(true_pos_total + false_pos_total)} total recall: {true_pos_total/true_labels_total} with {true_labels_total} total positive voxels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Val results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_total = 0\n",
    "false_pos_total = 0\n",
    "true_labels_total = 0\n",
    "spacing =  0.02\n",
    "thresholds = np.arange(spacing, 1.0, spacing)\n",
    "precisions = []\n",
    "recalls = []\n",
    "best_fscore = 0\n",
    "\n",
    "files = os.listdir(base_dir)\n",
    "files = [base_dir+f for f in files if \"val\" in f]\n",
    "files = [f for f in files if \"_Probabilities.h5\" in f]\n",
    "\n",
    "print(f\"{len(files)} total validation subvolumes\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    for fname_prob in files:\n",
    "\n",
    "        fname_im = fname_prob[:-17] + \".h5\"\n",
    "        f = h5py.File(fname_im, 'r')\n",
    "        im = f.get('image_2channel')\n",
    "        im_bg = im[0,:,:,:]\n",
    "        im_fg = im[1,:,:,:]\n",
    "\n",
    "        fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "        f = h5py.File(fname_lab, 'r')\n",
    "        gt = f.get('exported_data')\n",
    "        gt = gt[0,:,:,:]\n",
    "        pos_labels = gt == 2\n",
    "        num_pos_labels = np.sum(pos_labels)\n",
    "\n",
    "        f = h5py.File(fname_prob, 'r')\n",
    "        seg = f.get('exported_data')\n",
    "        seg = seg[1,:,:,:]\n",
    "        mask = seg > threshold\n",
    "\n",
    "        true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "        true_pos_total += true_pos\n",
    "        false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "        false_pos_total += false_pos\n",
    "        true_labels = np.sum(pos_labels)\n",
    "        true_labels_total += true_labels\n",
    "        \n",
    "    precision_total = true_pos_total/(true_pos_total + false_pos_total)\n",
    "    recall_total = true_pos_total/true_labels_total\n",
    "    fscore = 2/(1/precision_total+1/recall_total)\n",
    "    print(f\"Thresh: {threshold:.2f} --- Total prec.: {precision_total:.3f} total rec.: {recall_total:.3f} w/{true_labels_total} total pos voxels. F-score: {fscore:.4f}\")\n",
    "    if fscore > best_fscore:\n",
    "        best_fscore = fscore\n",
    "        best_prec = precision_total\n",
    "        best_recall = recall_total\n",
    "        best_threshold = threshold\n",
    "    precisions.append(precision_total) \n",
    "    recalls.append(recall_total)\n",
    "plt.plot(recalls, precisions, label='Prec-Rec Curve')\n",
    "plt.scatter([best_recall], [best_prec], c='red', label=f\"Best F-score: {best_fscore:.4f}\")\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('Validation Performance Brain' + brain)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_points(\"https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=Tizkn7VMAv6B6Q\", round=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname_prob in files:\n",
    "    fname_im = fname_prob[:-17] + \".h5\"\n",
    "    f = h5py.File(fname_im, 'r')\n",
    "    im = f.get('image_2channel')\n",
    "    im_bg = im[0,:,:,:]\n",
    "    im_fg = im[1,:,:,:]\n",
    "    im_endo = im[2,:,:,:]\n",
    "\n",
    "    fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "    f = h5py.File(fname_lab, 'r')\n",
    "    gt = f.get('exported_data')\n",
    "    gt = gt[0,:,:,:]\n",
    "    pos_labels = gt == 2\n",
    "    num_pos_labels = np.sum(pos_labels)\n",
    "\n",
    "    f = h5py.File(fname_prob, 'r')\n",
    "    seg = f.get('exported_data')\n",
    "    seg = seg[1,:,:,:]\n",
    "    mask = seg > best_threshold\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "    true_pos_total += true_pos\n",
    "    false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "    false_pos_total += false_pos\n",
    "    true_labels = np.sum(pos_labels)\n",
    "    true_labels_total += true_labels\n",
    "    \n",
    "\n",
    "    precision = true_pos/(true_pos + false_pos)\n",
    "    recall = true_pos/true_labels\n",
    "    fscore = 2/(1/precision+1/recall)\n",
    "    if fscore < 0.75:\n",
    "        print(fname_prob)\n",
    "        name = fname_prob.split(\"/\")[-1]\n",
    "        viewer = napari.Viewer(ndisplay=3)\n",
    "        viewer.add_image(im_bg, name=name[:-17])\n",
    "        viewer.add_image(im_fg)\n",
    "        viewer.add_image(im_endo)\n",
    "        viewer.add_labels(gt)\n",
    "        viewer.add_labels(mask, name=f\"p:{precision:.2f} r{recall:.2f}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_points(\"https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=V1ZmxgI5NeFOaw\", round=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make annotation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir = \"s3://smartspim-precomputed-volumes/2022_01_14/8613/axon_mask\"\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    encoding        = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution      = vol_bg.resolution, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = vol_bg.voxel_offset, # x,y,z offset in voxels from the origin\n",
    "    # mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 128, 128, 2 ], # units are voxels\n",
    "    volume_size     = vol_bg.volume_size, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol_mask = CloudVolume(dir, info=info)\n",
    "vol_mask.commit_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cannot write to https link, can write to s3 link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whole brain results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download from cloud\n",
    "centers = [[2304, 3840, 2100], [2560, 3840, 1800]]\n",
    "\n",
    "for i,center in enumerate(centers):\n",
    "    image_fg = vol_fg[center[0]:center[0]+256,center[1]:center[1]+256, center[2]:center[2]+300]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "    image_bg = vol_bg[center[0]:center[0]+256,center[1]:center[1]+256, center[2]:center[2]+300]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "    mask_s3 = vol_mask[center[0]:center[0]+256,center[1]:center[1]+256, center[2]:center[2]+300]\n",
    "    mask_s3 = mask_s3[:,:,:,0]\n",
    "\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/test_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/image_0.h5\"\n",
    "\n",
    "subprocess.run([\"/Applications/ilastik-1.3.3post3-OSX.app/Contents/ilastik-release/run_ilastik.sh\",  \"--headless\", \"--project=/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/matt_benchmark_formal.ilp\", fname], stdout=subprocess.PIPE, stderr=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample axon mask layer with igneous (this is only partial code, see igneous github for other code snippets)\n",
    "\n",
    "layer_path = \"s3://smartspim-precomputed-volumes/2021_07_15_Sert_Cre_R/axon_mask\"\n",
    "\n",
    "tasks = tc.create_downsampling_tasks(\n",
    "    layer_path, # e.g. 'gs://bucket/dataset/layer'\n",
    "    mip=0, # Start downsampling from this mip level (writes to next level up)\n",
    "    fill_missing=True, # Ignore missing chunks and fill them with black\n",
    "    axis='z', \n",
    "    num_mips=5, # number of downsamples to produce. Downloaded shape is chunk_size * 2^num_mip\n",
    "    chunk_size=None, # manually set chunk size of next scales, overrides preserve_chunk_size\n",
    "    preserve_chunk_size=True, # use existing chunk size, don't halve to get more downsamples\n",
    "    sparse=False, # for sparse segmentation, allow inflation of pixels against background\n",
    "    bounds=None, # mip 0 bounding box to downsample \n",
    "    encoding=None, # e.g. 'raw', 'compressed_segmentation', etc\n",
    "    delete_black_uploads=False, # issue a delete instead of uploading files containing all background\n",
    "    background_color=0, # Designates the background color\n",
    "    compress='gzip', # None, 'gzip', and 'br' (brotli) are options\n",
    "    factor=(2,2,2), # common options are (2,2,1) and (2,2,2)\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download higher mip\n",
    "\n",
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_07_15_Sert_Cre_R/axon_mask\"\n",
    "vol_mask_ds = CloudVolume(dir, parallel=1, mip=1, fill_missing=False)\n",
    "print(vol_mask_ds.shape)\n",
    "\n",
    "data = vol_mask_ds[:,:,0,0]\n",
    "data = data.astype('int8')\n",
    "print(data.nbytes)\n",
    "# print(np.unique(data))\n",
    "data = data[:,:,:,0]\n",
    "data = np.swapaxes(data, 0,2) #must do this\n",
    "print(data.shape)\n",
    "\n",
    "io.imsave(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/axon_mask_.tif\", data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample\n",
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/registered_2.img\"\n",
    "im = io.imread(im_path)\n",
    "print(im.shape)\n",
    "print(np.unique(im))\n",
    "\n",
    "im = im.astype('float')\n",
    "\n",
    "im_ds = ndi.zoom(im, (0.4,0.4,0.4))\n",
    "print(im_ds.shape)\n",
    "print(np.unique(im_ds))\n",
    "\n",
    "np.save(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/registered_3_ds.npy\", im_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain4/register/axon_mask_1_0.tif\"\n",
    "im = io.imread(im_path)\n",
    "print(im.shape)\n",
    "print(np.sum(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"brain3\"\n",
    "\n",
    "# im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain3/register/registered_3_ds.npy\"\n",
    "# im = np.load(im_path)\n",
    "# print(im.shape)\n",
    "\n",
    "# im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/brain3/register/axon_mask_3.tif\"\n",
    "# im_unreg = io.imread(im_path)\n",
    "# print(im_unreg.shape)\n",
    "\n",
    "\n",
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/\" + brain + \"/register/registered_1.img\"\n",
    "im_reg2 = io.imread(im_path)\n",
    "print(im_reg2.shape)\n",
    "\n",
    "# im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/\" + brain + \"/register/registered_3.img\"\n",
    "# im_reg3 = io.imread(im_path)\n",
    "# print(im_reg3.shape)\n",
    "\n",
    "# vol = CloudVolume(\n",
    "#     \"s3://open-neurodata/ara_2016/sagittal_10um/annotation_10um_2017\", mip=0, use_https=True\n",
    "# )\n",
    "# print(vol.shape)\n",
    "# atlas = vol[:,:,:,:]\n",
    "# atlas = np.squeeze(atlas).T\n",
    "# print(atlas.shape)\n",
    "# len(np.unique(atlas))\n",
    "\n",
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/ara_10um.tif\"\n",
    "atlas = io.imread(im_path)\n",
    "print(atlas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = ndi.gaussian_filter(im_reg2.astype('float'), sigma=3)\n",
    "#smooth = ndi.zoom(smooth, (0.4,0.4,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "animation_widget = AnimationWidget(viewer)\n",
    "viewer.window.add_dock_widget(animation_widget, area='right')\n",
    "#viewer.add_image(im)\n",
    "viewer.add_image(smooth)\n",
    "#viewer.add_image(im_reg2)\n",
    "#viewer.add_image(im_reg3)\n",
    "viewer.add_labels(atlas)\n",
    "napari.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in [180, 430, 680, 1030, 1280]:\n",
    "\n",
    "    slice = atlas[:,:,z]\n",
    "    slice_data = smooth[:,:,z]#np.sum(im_reg[:,:,z], axis=2)\n",
    "    mn = np.amin(slice_data)\n",
    "    print(np.unique(slice_data))\n",
    "    slice_data[slice == 0] = mn\n",
    "    labels = measure.label(slice)\n",
    "    #plt.imshow(labels)\n",
    "\n",
    "    borders = 0*labels\n",
    "    for label in np.unique(labels):\n",
    "        if label != 0:\n",
    "            mask = np.array(labels == label, dtype='int')\n",
    "            erode = np.array(ndi.binary_erosion(mask))\n",
    "            outline = mask - erode\n",
    "            borders += outline\n",
    "\n",
    "    print(np.unique(borders))\n",
    "    borders = borders.astype('float')\n",
    "    borders_layer = np.zeros((borders.shape[0],borders.shape[1],4))\n",
    "    for rgba in range(borders_layer.shape[2]):\n",
    "        borders_layer[:,:,rgba] = borders\n",
    "\n",
    "\n",
    "    slice_data = ndi.rotate(slice_data, 270)\n",
    "    plt.imshow(slice_data, cmap='inferno')\n",
    "    borders_layer = ndi.rotate(borders_layer, 270)\n",
    "    plt.imshow(borders_layer, cmap='gray')\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    fig.savefig('/Users/thomasathey/Desktop/' + str(z) + '.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = {}\n",
    "for x in tqdm(np.arange(0, vol_mask.shape[0], 128)):\n",
    "    x2 = np.amin([x+128, vol_mask.shape[0]])\n",
    "    for y in tqdm(np.arange(0, vol_mask.shape[1], 128), leave=False):\n",
    "        y2 = np.amin([x+128, vol_mask.shape[1]])\n",
    "        for z in tqdm(np.arange(0, vol_mask.shape[2], 128), leave=False):\n",
    "            z2 = np.amin([x+128, vol_mask.shape[2]])\n",
    "            labels = vol_reg[x:x2,y:y2,z:z2]\n",
    "            labels_unique = np.unique(labels)\n",
    "            mask = vol_mask[x:x2,y:y2,z:z2]\n",
    "\n",
    "            for unq in labels_unique:\n",
    "                if unq in volumes.keys():\n",
    "                    cur_vol = volumes[unq][1]\n",
    "                    cur_total = volumes[unq][0]\n",
    "                else:\n",
    "                    cur_vol = 0\n",
    "                    cur_total = 0\n",
    "                cur_vol += np.sum(mask[labels == unq])\n",
    "                cur_total += np.sum(labels == unq)\n",
    "                volumes[unq] = [cur_total, cur_vol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read quantification dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/brain3/vol_density.pkl\"\n",
    "with open(path, \"rb\") as f:\n",
    "   quantification_dict_3 = pickle.load(f)\n",
    "\n",
    "\n",
    "path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/brain4/vol_density.pkl\"\n",
    "with open(path, \"rb\") as f:\n",
    "   quantification_dict_4 = pickle.load(f)\n",
    "\n",
    "for key in quantification_dict_4.keys():\n",
    "   val = quantification_dict_4[key]\n",
    "   val = [float(v) for v in val]\n",
    "   val.reverse()\n",
    "   quantification_dict_4[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [688, 698, 1089, 583, 477, 803, 703, 1097, 549, 313, 1065]\n",
    "allen_regions = [315, 698, 1089, 703, 477, 803, 549, 1097, 313, 771, 354, 512] #https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantification_dicts = {\"3\": quantification_dict_3}#, \"4\": quantification_dict_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = json.load(open('/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/deisseroth/ara_structure_ontology.json','r'))\n",
    "\n",
    "tree = build_tree(f)\n",
    "stack = [tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max level: 10\n",
      "0\n",
      "0\n",
      "1451674.0\n",
      "379159936\n",
      "980271104.0\n",
      "48582134336\n"
     ]
    }
   ],
   "source": [
    "queue = [tree]\n",
    "cur_level = -1\n",
    "counter = 0\n",
    "G = nx.DiGraph()\n",
    "max_level = 0\n",
    "\n",
    "\n",
    "while len(queue) > 0:\n",
    "    node = queue.pop(0)\n",
    "    if node.level > max_level:\n",
    "        max_level = node.level\n",
    "    G.add_node(node.id, level = node.level, st_level = node.st_level, name = node.name, acronym = node.acronym, label = str(node.st_level) + \") \" +node.name)\n",
    "    for brain in quantification_dicts.keys():\n",
    "        G.nodes[node.id][brain + \" axon\"] = 0\n",
    "        G.nodes[node.id][brain + \" total\"] = 0\n",
    "    if node.parent_id is not None:\n",
    "        G.add_edge(node.parent_id, node.id)\n",
    "\n",
    "    queue += node.children\n",
    "\n",
    "i_test = 0\n",
    "print(f\"Max level: {max_level}\")\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])\n",
    "for brain,quantification_dict in quantification_dicts.items():\n",
    "    for key in quantification_dict.keys():\n",
    "        if key in G.nodes:\n",
    "            G.nodes[key][brain + \" axon\"] = G.nodes[key][brain + \" axon\"] + quantification_dict[key][1]\n",
    "            G.nodes[key][brain + \" total\"] = G.nodes[key][brain + \" total\"] + quantification_dict[key][0]\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    for lvl in range(max_level, 0, -1):\n",
    "        for node in G.nodes:\n",
    "            if G.nodes[node]['level'] == lvl:\n",
    "                parent = list(G.in_edges(node))[0][0]\n",
    "                G.nodes[parent][brain + \" axon\"] = G.nodes[parent][brain + \" axon\"] + G.nodes[node][brain + \" axon\"]\n",
    "                G.nodes[parent][brain + \" total\"] = G.nodes[parent][brain + \" total\"] + G.nodes[node][brain + \" total\"]\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas + seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'level'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'st_level'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'root'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'acronym'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'root'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0) root'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'3 axon'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VolumeCutout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.80271104e+08</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'3 total'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VolumeCutout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48582134336</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'level'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'st_level'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'root'\u001b[0m,\n",
       "    \u001b[32m'acronym'\u001b[0m: \u001b[32m'root'\u001b[0m,\n",
       "    \u001b[32m'label'\u001b[0m: \u001b[32m'0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m root'\u001b[0m,\n",
       "    \u001b[32m'3 axon'\u001b[0m: \u001b[1;35mVolumeCutout\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m9.80271104e+08\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'3 total'\u001b[0m: \u001b[1;35mVolumeCutout\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m48582134336\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G.nodes[997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating: Cerebral cortex\n",
      "Populating: Olfactory areas\n",
      "Populating: Hippocampal formation\n",
      "Populating: Claustrum\n",
      "Populating: Striatum\n",
      "Populating: Pallidum\n",
      "Populating: Cortical subplate\n",
      "Populating: Hypothalamus\n",
      "Populating: Thalamus\n",
      "Populating: Midbrain\n",
      "Populating: Hindbrain\n"
     ]
    }
   ],
   "source": [
    "totals = {}\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    total = 0\n",
    "    for node in G.nodes:\n",
    "        total += G.nodes[node][brain + \" axon\"]\n",
    "    totals[brain] = total\n",
    "\n",
    "axon_vols = []\n",
    "axon_denss = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "for region in regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    children = list(G.successors(region))\n",
    "    for child in children:\n",
    "        for brain in quantification_dicts.keys():\n",
    "            axon_vols.append(G.nodes[child][brain + \" axon\"]/totals[brain]*100)\n",
    "            if G.nodes[child][brain + \" total\"] == 0 and G.nodes[child][brain + \" axon\"] == 0:\n",
    "                axon_denss.append(0)\n",
    "            elif G.nodes[child][brain + \" total\"] == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                axon_denss.append(G.nodes[child][brain + \" axon\"]/G.nodes[child][brain + \" total\"]*100)\n",
    "\n",
    "            if brain in [\"3\" or \"4\"]:\n",
    "                gene.append(\"sert cre\")\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "            region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "d = {\"Percent Total Axon Volume (%)\": axon_vols, \"Axon Density (%)\": axon_denss, \"Gene\": gene, \"Subregion\": subregion_name, \"Region\": region_name}\n",
    "df = pd.DataFrame(data = d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Percent Total Axon Volume (%)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Neither the `x` nor `y` variable appears to be numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fq/9t66hqz51y5ddnygddgjtsmc0000gn/T/ipykernel_7398/61682350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Detected Output Axons'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Percent Total Axon Volume (%)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Subregion\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"Gene\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Distribution of Volume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3177\u001b[0m ):\n\u001b[1;32m   3178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3179\u001b[0;31m     plotter = _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[1;32m   3180\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3181\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1582\u001b[0m                  errwidth, capsize, dodge):\n\u001b[1;32m   1583\u001b[0m         \u001b[0;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0m\u001b[1;32m   1585\u001b[0m                                  order, hue_order, units)\n\u001b[1;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# Figure out the plotting orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             orient = infer_orient(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             )\n",
      "\u001b[0;32m~/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36minfer_orient\u001b[0;34m(x, y, orient, require_numeric)\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrequire_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"numeric\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Neither the `x` nor `y` variable appears to be numeric.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Neither the `x` nor `y` variable appears to be numeric."
     ]
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle('Detected Output Axons')\n",
    "\n",
    "sns.barplot(ax = axes[0], x = \"Percent Total Axon Volume (%)\", y = \"Subregion\",  hue= \"Gene\", data=df)\n",
    "axes[0].set_title(\"Distribution of Volume\")\n",
    "\n",
    "sns.barplot(ax = axes[1], x = \"Axon Density (%)\", y = \"Subregion\",  hue= \"Gene\", data=df)\n",
    "axes[1].set_title(\"Density\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Allen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    total = 0\n",
    "    for node in G.nodes:\n",
    "        total += G.nodes[node][brain + \" axon\"]\n",
    "    totals[brain] = total\n",
    "\n",
    "axon_denss = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "subregions_list = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    children = list(G.successors(region))\n",
    "    for child in children:\n",
    "        if child not in subregions_list:\n",
    "            subregions_list.append(child)\n",
    "\n",
    "\n",
    "        for brain in quantification_dicts.keys():\n",
    "            if G.nodes[child][brain + \" total\"] == 0 and G.nodes[child][brain + \" axon\"] == 0:\n",
    "                axon_denss.append(0)\n",
    "            elif G.nodes[child][brain + \" total\"] == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                axon_denss.append(G.nodes[child][brain + \" axon\"]/G.nodes[child][brain + \" total\"])\n",
    "\n",
    "            if brain in [\"3\", \"4\"]:\n",
    "                gene.append(brain)\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "\n",
    "        \n",
    "    region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse('/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/deisseroth/sert_exp.xml')\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "        if region in subregions_list and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(f\"id: {region} hemi: {hemi}, density: {density}, name: {name}\")\n",
    "            subregion_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "\n",
    "\n",
    "\n",
    "d = {\"Axon Density\": axon_denss, \"Gene\": gene, \"Subregion\": subregion_name}\n",
    "df = pd.DataFrame(data = d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(20, 10))\n",
    "fig.suptitle('Detected Output Axons')\n",
    "\n",
    "sns.barplot(x = \"Axon Density\", y = \"Subregion\",  hue= \"Gene\", data=df)\n",
    "axes.set_title(\"Density\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    total = 0\n",
    "    for node in G.nodes:\n",
    "        total += G.nodes[node][brain + \" axon\"]\n",
    "    totals[brain] = total\n",
    "\n",
    "axon_denss = []\n",
    "gene = []\n",
    "region_name = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    for brain in quantification_dicts.keys():\n",
    "        if G.nodes[region][brain + \" total\"] == 0 and G.nodes[region][brain + \" axon\"] == 0:\n",
    "            axon_denss.append(0)\n",
    "        elif G.nodes[region][brain + \" total\"] == 0:\n",
    "            raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "        else:\n",
    "            axon_denss.append(G.nodes[region][brain + \" axon\"]/G.nodes[region][brain + \" total\"])\n",
    "\n",
    "\n",
    "        if brain in [\"3\", \"4\"]:\n",
    "            gene.append(brain)\n",
    "        \n",
    "        region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse('/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/deisseroth/sert_exp.xml')\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "        if region in allen_regions and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(f\"id: {region} hemi: {hemi}, density: {density}, name: {name}\")\n",
    "            region_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "\n",
    "\n",
    "\n",
    "d = {\"Axon Density\": axon_denss, \"Gene\": gene, \"Region\": region_name}\n",
    "df = pd.DataFrame(data = d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(20, 10))\n",
    "fig.suptitle('Detected Output Axons')\n",
    "\n",
    "sns.barplot(x = \"Axon Density\", y = \"Region\",  hue= \"Gene\", order = list(df[df[\"Gene\"] == \"Allen\"].sort_values('Axon Density', ascending=False).loc[:,'Region']), data=df)\n",
    "axes.set_title(\"Density\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
