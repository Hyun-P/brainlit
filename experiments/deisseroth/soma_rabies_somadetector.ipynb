{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "import napari\n",
    "from skimage import io\n",
    "import random\n",
    "import h5py\n",
    "from skimage import measure\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import subprocess\n",
    "import tables\n",
    "from napari_animation import AnimationWidget\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from parse_ara import *\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import brainrender\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import skeletonize\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from soma_rabies_somadetector_data import brain2paths, brain2centers\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"8557\"\n",
    "channel = \"3channel\"\n",
    "dir = brain2paths[brain][0]\n",
    "vol_fg = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "dir = brain2paths[brain][1]\n",
    "vol_bg = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "dir = brain2paths[brain][2]\n",
    "vol_endo = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "print(vol_fg.shape)\n",
    "\n",
    "soma_centers = brain2centers[brain][0][0]\n",
    "nonsoma_centers = brain2centers[brain][1][0]\n",
    "\n",
    "print(f\"{len(soma_centers)} soma centers\")\n",
    "print(f\"{len(nonsoma_centers)} nonsoma centers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fg = vol_fg[:,:,1590:1610,0]\n",
    "fg = np.squeeze(fg)\n",
    "fg = np.array(fg)\n",
    "\n",
    "\n",
    "bg = vol_bg[:,:,1590:1610,0]\n",
    "bg = np.squeeze(bg)\n",
    "bg = np.array(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.Viewer(ndisplay=2)\n",
    "viewer.add_image(fg, contrast_limits = [0, 65535])\n",
    "viewer.add_image(bg, contrast_limits = [0, 65535])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_name = \"BSsomas_train\"\n",
    "\n",
    "type = \"pos\"\n",
    "for i, center in enumerate(soma_centers):\n",
    "    if i <10:\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    image_fg = vol_fg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "    image_bg = vol_bg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "    image_endo = vol_endo[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "    image = np.squeeze(np.stack([image_fg, image_bg, image_endo], axis=0))\n",
    "        \n",
    "    fname = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/brain{brain}/{channel}/{dset_name}/{int(center[0])}_{int(center[1])}_{int(center[2])}_{type}.h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_3channel\", data=image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"neg\"\n",
    "for i, center in enumerate(nonsoma_centers):\n",
    "    if i < 10:\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    image_fg = vol_fg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "    image_bg = vol_bg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "    image_endo = vol_endo[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "\n",
    "    image = np.squeeze(np.stack([image_fg, image_bg, image_endo], axis=0))\n",
    "        \n",
    "    fname = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/brain{brain}/{channel}/{dset_name}/{int(center[0])}_{int(center[1])}_{int(center[2])}_{type}.h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_3channel\", data=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "files_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/brain{brain}/{channel}/test/\"\n",
    "onlyfiles = [f for f in listdir(files_dir) if isfile(join(files_dir, f))]\n",
    "#test_files = [f for f in onlyfiles if f[:4] == \"test\"]\n",
    "test_files = [f for f in onlyfiles if \"Probabilities\" in f] #\"probabilities\"\n",
    "print(test_files)\n",
    "\n",
    "size_thresh = 500\n",
    "\n",
    "thresholds = list(np.arange(0.0,1.0,0.02))\n",
    "\n",
    "for threshold in thresholds:\n",
    "    tot_pos = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    for filename in tqdm(test_files, disable=True):\n",
    "        if filename == \"3972_1636_1575_pos_Probabilities.h5\":\n",
    "            newpos = 2\n",
    "        else:\n",
    "            newpos = 1\n",
    "\n",
    "        fname = files_dir + filename\n",
    "        f = h5py.File(fname, \"r\")\n",
    "        pred = f.get(\"exported_data\")\n",
    "        pred = pred[0,:,:,:]\n",
    "        mask = pred>threshold\n",
    "        labels = measure.label(mask)\n",
    "        props = measure.regionprops(labels)\n",
    "\n",
    "        if \"pos\" in filename: \n",
    "            num_detected = 0\n",
    "            tot_pos += newpos\n",
    "            for prop in props:\n",
    "                if prop[\"area\"] > size_thresh:\n",
    "                    if num_detected < newpos:\n",
    "                        true_pos += 1\n",
    "                        num_detected += 1\n",
    "                    else:\n",
    "                        false_pos += 1\n",
    "        elif \"neg\" in filename:\n",
    "            for prop in props:\n",
    "                if prop[\"area\"] > size_thresh:\n",
    "                    false_pos += 1\n",
    "\n",
    "    recall = true_pos/tot_pos\n",
    "    recalls.append(recall)\n",
    "    if true_pos + false_pos == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = true_pos/(true_pos + false_pos)\n",
    "    precisions.append(precision)\n",
    "    if precision == 0 and recall == 0:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = 2*precision*recall/(precision+recall)\n",
    "    print(f\"threshold: {threshold}: precision: {precision}, recall: {recall}, f-score: {fscore} for {tot_pos} positive samples in {len(test_files)} images\")\n",
    "\n",
    "fscores = [2*precision*recall/(precision+recall) if (precision != 0 and recall != 0) else 0 for precision,recall in zip(precisions, recalls) ]\n",
    "dict = {'Recall': recalls, 'Precision' : precisions, 'F-score': fscores, 'Threshold': thresholds}\n",
    "df = pd.DataFrame(dict)\n",
    "max_fscore = df[\"F-score\"].max()\n",
    "best_threshold = float(df.loc[df['F-score'] == max_fscore]['Threshold'].iloc[0])\n",
    "best_rec = float(df.loc[df['F-score'] == max_fscore]['Recall'].iloc[0])\n",
    "best_prec = float(df.loc[df['F-score'] == max_fscore]['Precision'].iloc[0])\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "sns.lineplot(data=df, x=\"Recall\", y=\"Precision\", estimator=np.amax, ci=False)\n",
    "plt.scatter(best_rec, best_prec, c='r', label=f\"Max f-score: {max_fscore:.2f} thresh:{best_threshold:.2f}\")\n",
    "plt.xlim([0, 1.1])\n",
    "plt.ylim([0, 1.1])\n",
    "plt.title(f\"Brain {brain} Validation: {tot_pos}+ {len(test_files)-tot_pos}-\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(test_files, disable=True):\n",
    "    print(f\"*************File: {filename}*********\")\n",
    "    if filename == \"3972_1636_1575_pos_Probabilities.h5\":\n",
    "        newpos = 2\n",
    "    else:\n",
    "        newpos = 1\n",
    "\n",
    "    im_fname = files_dir + filename[:-17] + \".h5\"\n",
    "    fname = files_dir + filename\n",
    "    f = h5py.File(fname, \"r\")\n",
    "    pred = f.get(\"exported_data\")\n",
    "    pred = pred[0,:,:,:]\n",
    "    mask = pred>best_threshold\n",
    "    labels = measure.label(mask)\n",
    "    props = measure.regionprops(labels)\n",
    "\n",
    "    if \"pos\" in filename: \n",
    "        num_detected = 0\n",
    "        tot_pos += newpos\n",
    "        for prop in props:\n",
    "            area = prop[\"area\"]\n",
    "            if area > size_thresh:\n",
    "                print(f\"area of detected object: {area}\")\n",
    "                if num_detected < newpos:\n",
    "                    true_pos += 1\n",
    "                    num_detected += 1\n",
    "                else:\n",
    "                    print(f\"Soma false positive Area: {area}\")\n",
    "                    f = h5py.File(im_fname, \"r\")\n",
    "                    im = f.get(\"image_3channel\")\n",
    "                    viewer = napari.Viewer(ndisplay=3)\n",
    "                    viewer.add_image(im[0,:,:,:])\n",
    "                    viewer.add_image(im[1,:,:,:])\n",
    "                    viewer.add_image(im[2,:,:,:])\n",
    "                    viewer.add_labels(mask)\n",
    "                    viewer.add_labels(labels == prop[\"label\"], name=f\"soma false positive area: {area}\")\n",
    "                    false_pos += 1\n",
    "        if num_detected == 0:\n",
    "            print(f\"Soma false negative\")\n",
    "            f = h5py.File(im_fname, \"r\")\n",
    "            im = f.get(\"image_3channel\")\n",
    "            viewer = napari.Viewer(ndisplay=3)\n",
    "            viewer.add_image(im[0,:,:,:])\n",
    "            viewer.add_image(im[1,:,:,:])\n",
    "            viewer.add_image(im[2,:,:,:])\n",
    "            viewer.add_labels(mask, name=\"Soma false negative\")\n",
    "    elif \"neg\" in filename:\n",
    "        for prop in props:\n",
    "            area = prop[\"area\"]\n",
    "            if area > size_thresh:\n",
    "                print(f\"Nonsoma false positive Area: {area}\")\n",
    "                f = h5py.File(im_fname, \"r\")\n",
    "                im = f.get(\"image_3channel\")\n",
    "                viewer = napari.Viewer(ndisplay=3)\n",
    "                viewer.add_image(im[0,:,:,:])\n",
    "                viewer.add_image(im[1,:,:,:])\n",
    "                viewer.add_image(im[2,:,:,:])\n",
    "                viewer.add_labels(mask)\n",
    "                viewer.add_labels(labels == prop[\"label\"], name=f\"nonsoma false positive area: {area}\")\n",
    "                false_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make point layer - ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "point_path = \"precomputed://https://dlab-colm.neurodata.io/2021_10_06/8557/point_preds\"\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    # raw, jpeg, compressed_segmentation, fpzip, kempressed, compresso\n",
    "    encoding        = 'raw', \n",
    "    resolution      = [4, 4, 40], # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = [0, 0, 0], # x,y,z offset in voxels from the origin\n",
    "    mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 512, 512, 16 ], # units are voxels\n",
    "    volume_size     = [ 250000, 250000, 25000 ], # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(point_path, info=info)\n",
    "vol.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_somas = []\n",
    "for soma in somas:\n",
    "    if soma[2] <= 3000:\n",
    "        new_somas.append(soma)\n",
    "len(new_somas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_ra = np.array(new_somas)\n",
    "plt.hist(soma_ra[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer(ndisplay=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fg = vol_fg[3100:3500,4500:4900,1400:1800, 0]\n",
    "im_bg = vol_bg[3100:3500,4500:4900,1400:1800, 0]\n",
    "im_endo = vol_endo[3100:3500,4500:4900,1400:1800, 0]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(np.squeeze(im_fg))\n",
    "viewer.add_image(np.squeeze(im_bg))\n",
    "viewer.add_image(np.squeeze(im_endo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ilastik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fg = vol_fg[3100:3500,4500:4900,1400:1800, 0]\n",
    "im_bg = vol_bg[3100:3500,4500:4900,1400:1800, 0]\n",
    "im_endo = vol_endo[3100:3500,4500:4900,1400:1800, 0]\n",
    "\n",
    "image = np.squeeze(np.stack([im_fg, im_bg, im_endo], axis=0))\n",
    "fname = \"/Users/thomasathey/Desktop/im.h5\"\n",
    "\n",
    "with h5py.File(fname, \"w\") as f:\n",
    "    dset = f.create_dataset(\"image_3channel\", data=image)\n",
    "\n",
    "subprocess.run([\"/Applications/ilastik-1.3.3post3-OSX.app/Contents/ilastik-release/run_ilastik.sh\", \"--headless\", \"--project=/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/matt_soma_rabies_pix_3ch.ilp\", fname], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"/Users/thomasathey/Desktop/im_Probabilities.h5\", \"r\")\n",
    "pred = f.get(\"exported_data\")\n",
    "\n",
    "pred = pred[0,:,:,:]\n",
    "\n",
    "mask = pred > 0.55\n",
    "labels = measure.label(mask)\n",
    "props = measure.regionprops(labels)\n",
    "\n",
    "results = []\n",
    "for prop in props:\n",
    "    if prop[\"area\"] > 500:\n",
    "        location = list(np.add((0,0,0), prop[\"centroid\"]))\n",
    "        print(location)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(np.squeeze(im_fg))\n",
    "viewer.add_labels(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "new_pts = []\n",
    "for point in a:\n",
    "    first = math.isclose(point[0],int(point[0]))\n",
    "    second = math.isclose(np.abs(point[1]-int(point[1])), 0.5)\n",
    "    third = math.isclose(np.abs(point[2]-int(point[2])), 0.5)\n",
    "    if first and second and third:\n",
    "        continue\n",
    "    else:\n",
    "        new_pts.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import napari\n",
    "\n",
    "subvol_number = -1 #change value here for different center point, valid values 0-9\n",
    "r = 400 #change for voxel radius\n",
    "\n",
    "vol = CloudVolume(\"precomputed://https://dlab-colm.neurodata.io/2021_10_06/8557/Ch_647\", parallel=1, mip=0, fill_missing=False)\n",
    "print(f\"Total volume size: {vol.shape}\")\n",
    "\n",
    "\n",
    "centers = [[1042.743408203125, 2647.38671875, 1224.5],\n",
    "            [2430.76171875, 3053.81494140625, 713.5],\n",
    "            [1780.8623046875, 2691.490234375, 1538.5001220703125],\n",
    "            [1642.8656005859375, 3693.246337890625, 1540.4998779296875],\n",
    "            [1924.112060546875, 2812.427978515625, 1539.5],\n",
    "            [2228.993896484375, 3124.892333984375, 710.4999389648438],\n",
    "            [976.0220336914062, 2615.152587890625, 1295.4998779296875],\n",
    "            [2973.654296875, 5300.09912109375, 900.5],\n",
    "            [3070.7158203125, 5557.70166015625, 1127.5000610351562],\n",
    "             [780.11474609375, 2957.698486328125, 1287.5]]\n",
    "\n",
    "center = centers[subvol_number]\n",
    "center = [int(c) for c in center]\n",
    "\n",
    "center = [536, 6588, 2800]\n",
    "\n",
    "lower = [c-r for c in center]\n",
    "upper = [c+r for c in center]\n",
    "print(f\"Downloading bbox: {lower} to {upper}\")\n",
    "\n",
    "\n",
    "\n",
    "im = vol[lower[0]:upper[0], lower[1]:upper[1], lower[2]:upper[2],0]\n",
    "im = np.squeeze(im)\n",
    "\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "heights = np.array([70, 67, 73, 70, 66, 67, 68, 68, 74, 69, 71, 67, 70, 67, 67, 70, 67, 72, 71, 71])\n",
    "bouldering = np.arange(1,len(heights)+1)\n",
    "lead = np.array([11, 14, 4, 15, 2, 6, 1, 7, 9, 16, 5, 17, 12, 3, 8, 10, 13, 20, 19, 18])\n",
    "speed = [3, 2, 18, 16, 6, 19, 12, 20, 11, 5, 10, 15, 8, 7, 14, 9, 4, 1, 17, 13]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "m, b = np.polyfit(heights, bouldering, 1)\n",
    "coef, p = pearsonr(heights, bouldering)\n",
    "axs[0].scatter(heights, bouldering)\n",
    "axs[0].plot(heights, m*heights+b, label=f\"m={m:.2f}, coef={coef:.2f}, p={p:.2f}\")\n",
    "axs[0].set_title(\"Bouldering\")\n",
    "axs[0].set_ylabel(\"Finish in Olympic Qualifying Round\")\n",
    "axs[0].set_xlabel(\"Height (in.)\")\n",
    "axs[0].legend()\n",
    "\n",
    "m, b = np.polyfit(heights, lead, 1)\n",
    "coef, p = pearsonr(heights, lead)\n",
    "axs[1].scatter(heights, lead)\n",
    "axs[1].plot(heights, m*heights+b, label=f\"m={m:.2f}, coef={coef:.2f}, p={p:.2f}\")\n",
    "axs[1].set_title(\"Lead Climbing\")\n",
    "axs[1].legend()\n",
    "\n",
    "m, b = np.polyfit(heights, speed, 1)\n",
    "coef, p = pearsonr(heights, speed)\n",
    "axs[2].scatter(heights, speed)\n",
    "axs[2].plot(heights, m*heights+b, label=f\"m={m:.2f}, coef={coef:.2f}, p={p:.2f}\")\n",
    "axs[2].set_title(\"Speed Climbing\")\n",
    "axs[2].legend()\n",
    "fig.set_figwidth(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(heights, lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
