{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6  ('env': venv)"
  },
  "interpreter": {
   "hash": "c48f87b51193a18c36f6ec1b39da40df380a4c3fb2fa54b3e413dc2378ec9052"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "In order to run this notebook, you must have generated data with random dropout of trace vertices. This can be done by uncommenting the bottom of `generate_trace_data.ipynb`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = 300\n",
    "\n",
    "\n",
    "def classify_height(row):\n",
    "    height = row[\"height\"]\n",
    "    if height <= 2:\n",
    "        return height\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def numerical_class(row):\n",
    "    _class = row[\"class\"]\n",
    "    if _class == \"primary\":\n",
    "        return 0\n",
    "    if _class == \"collateral\":\n",
    "        return 1\n",
    "    if _class == \"terminal\":\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify brain1 or brain2 below\n",
    "brain = \"brain1\"\n",
    "\n",
    "root_dir = Path(os.path.abspath(\"\")).parents[1]\n",
    "experiment_dir = os.path.join(root_dir, \"axon_geometry\")\n",
    "data_dir = os.path.join(experiment_dir, \"data\", brain)\n",
    "segments_swc_dir = os.path.join(data_dir, \"segments_swc\")\n",
    "print(f\"Directory where swcs reside: {segments_swc_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(f\"****************Iter: {i}********************\")\n",
    "    dropout_version = \"10pct_iter\" + str(i)\n",
    "    trace_data_dir = os.path.join(data_dir, \"trace_data\")\n",
    "    trace_data_dir = os.path.join(trace_data_dir, \"1\")\n",
    "    trace_data_dir = os.path.join(trace_data_dir, dropout_version)\n",
    "    df_path = os.path.join(trace_data_dir, \"df.csv\")\n",
    "    if os.path.exists(df_path):\n",
    "        df = pd.read_csv(df_path)\n",
    "    else:\n",
    "        df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"seg_id\",\n",
    "                \"class\",\n",
    "                \"height\",\n",
    "                \"log_seg_length\",\n",
    "                \"measure\",\n",
    "                \"value\",\n",
    "                \"log_value\",\n",
    "            ]\n",
    "        )\n",
    "        for i in tqdm(np.arange(0, max_id)):\n",
    "            i = int(i)\n",
    "            trace_data_path = os.path.join(trace_data_dir, \"{}.npy\".format(i))\n",
    "            if os.path.exists(trace_data_path) is True:\n",
    "                trace_data = np.load(trace_data_path, allow_pickle=True)\n",
    "\n",
    "                for node in trace_data:\n",
    "                    seg_length = node[\"seg_length\"]\n",
    "                    height = node[\"height\"]\n",
    "                    _class = node[\"class\"]\n",
    "                    mean_curvature = node[\"mean_curvature\"]\n",
    "                    mean_torsion = node[\"mean_torsion\"]\n",
    "\n",
    "                    log_seg_length = np.log10(seg_length)\n",
    "\n",
    "                    log_mean_curvature = np.log10(mean_curvature)\n",
    "                    df = df.append(\n",
    "                        {\n",
    "                            \"seg_id\": i,\n",
    "                            \"height\": height,\n",
    "                            \"class\": _class,\n",
    "                            \"log_seg_length\": log_seg_length,\n",
    "                            \"measure\": \"curvature\",\n",
    "                            \"value\": mean_curvature,\n",
    "                            \"log_value\": log_mean_curvature,\n",
    "                        },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "\n",
    "                    log_mean_torsion = np.log10(mean_torsion)\n",
    "                    df = df.append(\n",
    "                        {\n",
    "                            \"seg_id\": i,\n",
    "                            \"height\": height,\n",
    "                            \"class\": _class,\n",
    "                            \"log_seg_length\": log_seg_length,\n",
    "                            \"measure\": \"torsion\",\n",
    "                            \"value\": mean_torsion,\n",
    "                            \"log_value\": log_mean_torsion,\n",
    "                        },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "        df.to_csv(df_path)\n",
    "    df[\"class\"] = df.apply(numerical_class, axis=1)\n",
    "    df[\"height_class\"] = df.apply(classify_height, axis=1)\n",
    "\n",
    "    measures = [\"curvature\", \"torsion\"]\n",
    "\n",
    "    classes = {0: \"primary\", 1: \"collateral\", 2: \"terminal\"}\n",
    "    n = len(classes)\n",
    "    matrix_pairs = np.triu(np.ones((n, n)), k=1)\n",
    "    (coord_pairs_x, coord_pairs_y) = np.where(matrix_pairs == 1)\n",
    "\n",
    "    for measure in measures:\n",
    "        for class_1, class_2 in zip(coord_pairs_x, coord_pairs_y):\n",
    "            Y1 = []\n",
    "            Y2 = []\n",
    "            segment_numbers = []\n",
    "            X_class = []\n",
    "            neuron_id = 0\n",
    "            # collect data from all neurons\n",
    "            for i in np.arange(0, max_id):\n",
    "                sample_query = df.loc[\n",
    "                    (df[\"seg_id\"] == i)\n",
    "                    & ((df[\"class\"] == class_1))\n",
    "                    & (df[\"measure\"] == measure)\n",
    "                ]\n",
    "                num_segments = len(sample_query.index)\n",
    "                if num_segments > 0:\n",
    "                    Y1.append(np.mean(sample_query[\"value\"].to_numpy()))\n",
    "                    sample_query = df.loc[\n",
    "                        (df[\"seg_id\"] == i)\n",
    "                        & ((df[\"class\"] == class_2))\n",
    "                        & (df[\"measure\"] == measure)\n",
    "                    ]\n",
    "                    Y2.append(np.mean(sample_query[\"value\"].to_numpy()))\n",
    "\n",
    "            # Sign Test\n",
    "            dif = np.subtract(Y1, Y2)\n",
    "            k = np.sum(dif > 0)\n",
    "            n = dif.shape[0]\n",
    "            upper_bool = k > n // 2\n",
    "            if upper_bool:\n",
    "                p = np.sum(scipy.stats.binom.pmf(range(k, n + 1), n=n, p=0.5))\n",
    "            else:\n",
    "                p = np.sum(scipy.stats.binom.pmf(range(0, k + 1), n=n, p=0.5))\n",
    "\n",
    "            if p < 0.05 / 12:\n",
    "                if upper_bool:\n",
    "                    symb = \">\"\n",
    "                else:\n",
    "                    symb = \"<\"\n",
    "                print(f\"{classes[class_1]} {symb} {classes[class_2]} in {measure}\")\n",
    "                print(f\"p-val was: {p}\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"No difference between {classes[class_1]} and {classes[class_2]} in {measure}\"\n",
    "                )\n",
    "                print(f\"p-val was: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}