{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from skimage import io, measure\n",
    "import numpy as np\n",
    "import h5py\n",
    "from brainlit.preprocessing import image_process\n",
    "from brainlit.algorithms.connect_fragments import dynamic_programming_viterbi2\n",
    "import scipy.ndimage as ndi\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import napari\n",
    "import networkx as nx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_dir = Path(os.path.abspath(\"\")).parents[0]\n",
    "data_dir = os.path.join(root_dir, \"data\", \"example\")\n",
    "im_path = os.path.join(data_dir, \"image.tif\")\n",
    "probs_path = os.path.join(data_dir, \"probabilities.h5\")\n",
    "coords_path = os.path.join(data_dir, \"manual_coords.csv\")\n",
    "\n",
    "res = [0.3, 0.3, 1]\n",
    "\n",
    "im_og = io.imread(im_path, plugin=\"tifffile\")\n",
    "print(f\"Image shape: {im_og.shape}\")\n",
    "\n",
    "coords = np.genfromtxt(coords_path, delimiter=\",\")\n",
    "coords = coords.astype(int)\n",
    "coords_list = list(coords)\n",
    "coords_list = [list(c) for c in coords_list]\n",
    "coords_list.reverse()\n",
    "print(f\"coords shape: {coords.shape}\")\n",
    "soma_coords = [list(coords[0, :])]\n",
    "axon_coords = [list(coords[-1, :])]\n",
    "\n",
    "f = h5py.File(probs_path, \"r\")\n",
    "pred = f.get(\"exported_data\")\n",
    "pred = pred[:, :, :, 1]\n",
    "im_processed = pred\n",
    "\n",
    "threshold = 0.9  # 0.1\n",
    "labels = measure.label(im_processed > threshold)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process Components into Fragments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_labels = image_process.split_frags(\n",
    "    soma_coords, labels, im_processed, threshold, res\n",
    ")\n",
    "\n",
    "_, axon_lbls = image_process.label_points(new_labels, axon_coords, res)\n",
    "axon_lbl = axon_lbls[0]\n",
    "axon_mask = new_labels == axon_lbl\n",
    "\n",
    "_, soma_lbls = image_process.label_points(new_labels, soma_coords, res)\n",
    "soma_lbl = soma_lbls[0]\n",
    "soma_mask = new_labels == soma_lbl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View Data and Processed Labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "\n",
    "viewer.add_image(im_og)\n",
    "viewer.add_labels(labels)\n",
    "viewer.add_labels(new_labels)\n",
    "viewer.add_labels(axon_mask)\n",
    "viewer.add_labels(soma_mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reconstruct Axon"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mpnp = dynamic_programming_viterbi2.most_probable_neuron_path(\n",
    "    image=im_og.astype(float),\n",
    "    labels=new_labels,\n",
    "    soma_lbls=soma_lbls,\n",
    "    resolution=(0.3, 0.3, 1),\n",
    "    coef_dist=10,\n",
    "    coef_curv=1000,\n",
    ")\n",
    "mpnp.frags_to_lines()\n",
    "mpnp.reset_dists(type=\"all\")\n",
    "mpnp.compute_all_costs_dist(\n",
    "    point_point_func=mpnp.point_point_dist, point_blob_func=mpnp.point_blob_dist\n",
    ")\n",
    "mpnp.compute_all_costs_int()\n",
    "mpnp.create_nx_graph()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choose which state to start from"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "axon_lbl = axon_lbls[0]\n",
    "\n",
    "start1 = mpnp.comp_to_states[axon_lbl][0]\n",
    "start2 = mpnp.comp_to_states[axon_lbl][1]\n",
    "end_state = mpnp.comp_to_states[soma_lbl][0]\n",
    "\n",
    "# In this example, I know which state we should start from. Otherwise, the user should examine state1 and state2 and decide\n",
    "start = start2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_states = nx.shortest_path(mpnp.nxGraph, start, end_state, weight=\"weight\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot Result"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_comps = []\n",
    "for state in path_states:\n",
    "    path_comps.append(mpnp.state_to_comp[state][1])\n",
    "print(f\"path sequence: {path_states}\")\n",
    "print(f\"component sequence: {path_comps}\")\n",
    "\n",
    "path_mask = 0 * new_labels\n",
    "for i, label in enumerate(path_comps):\n",
    "    path_mask[new_labels == label] = i + 1\n",
    "\n",
    "soma_mask = 0 * new_labels\n",
    "for soma_lbl in mpnp.soma_lbls:\n",
    "    soma_mask[new_labels == soma_lbl] = soma_lbl\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(mpnp.image)\n",
    "viewer.add_labels(new_labels)\n",
    "viewer.add_labels(path_mask)\n",
    "viewer.add_labels(soma_mask)\n",
    "viewer.add_labels(new_labels == axon_lbl)\n",
    "\n",
    "viewer.add_points([axon_coords[0]], face_color=\"red\", size=10)\n",
    "\n",
    "lines = []\n",
    "cumul_cost = 0\n",
    "for s, state in enumerate(path_states):\n",
    "    if s > 0:\n",
    "        dist_cost = mpnp.cost_mat_dist[path_states[s - 1], state]\n",
    "        int_cost = mpnp.cost_mat_int[path_states[s - 1], state]\n",
    "        cumul_cost += dist_cost + int_cost\n",
    "        print(\n",
    "            f\"Trans. #{s}: dist cost state {path_states[s-1]}->state {state}, comp {mpnp.state_to_comp[path_states[s-1]][1]}->comp {mpnp.state_to_comp[state][1]}: {dist_cost:.2f}, int cost: {int_cost:.2f}, cum. cost: {cumul_cost:.2f}\"\n",
    "        )\n",
    "    if mpnp.state_to_comp[state][0] == \"fragment\":\n",
    "        lines.append(list(mpnp.state_to_comp[state][2][\"coord1\"]))\n",
    "        lines.append(list(mpnp.state_to_comp[state][2][\"coord2\"]))\n",
    "    elif mpnp.state_to_comp[path_states[s - 1]][0] == \"fragment\":\n",
    "        lines.append(\n",
    "            list(mpnp.state_to_comp[path_states[s - 1]][2][\"soma connection point\"])\n",
    "        )\n",
    "lines.insert(0, coords_list[0])\n",
    "lines.append(coords_list[-1])\n",
    "viewer.add_shapes(lines, shape_type=\"path\", edge_color=\"blue\", edge_width=2)\n",
    "viewer.add_shapes(coords_list, shape_type=\"path\", edge_color=\"green\", edge_width=2)\n",
    "\n",
    "viewer.camera.angles = [0, -90, 180]\n",
    "napari.run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)"
  },
  "interpreter": {
   "hash": "c6a82fd7624a30cb39f184f8a867df460926136b3ed0e9f03cd044bdf3194e37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}